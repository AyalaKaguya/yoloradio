"""éªŒè¯ç®¡ç†å™¨ - YOLOæ¨¡å‹éªŒè¯åŠŸèƒ½

å˜æ›´è¦ç‚¹ï¼š
- å°†éªŒè¯æ‰§è¡Œæ”¹ä¸ºé€šè¿‡å­è¿›ç¨‹è°ƒç”¨ `yolo.exe val` å¹¶å¼‚æ­¥è¯»å–æ ‡å‡†è¾“å‡ºï¼Œå®æ—¶å†™å…¥æ—¥å¿—ã€‚
- æä¾›æ›´è´´è¿‘å‘½ä»¤è¡Œçš„æ—¥å¿—è¾“å‡ºï¼Œè€Œä¸æ˜¯ä»…ç”¨å†…ç½®æç¤ºè¯­ã€‚
- åœ¨å¯ç”¨æ—¶è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆGPU/CPUï¼‰ã€‚
- ç»“æŸåå°½é‡ä»ç»“æœæ–‡ä»¶ä¸­è§£ææŒ‡æ ‡ï¼ˆresults.json / results.csvï¼‰ã€‚
"""

from __future__ import annotations

import json
import logging
import os
import re
import subprocess
import sys
import tempfile
import threading
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml

from .dataset_manager import Dataset, dataset_manager
from .paths import PROJECT_DIR

logger = logging.getLogger(__name__)


def _clean_terminal_output(text: str) -> str:
    """æ¸…ç†ç»ˆç«¯è¾“å‡ºä¸­çš„æ§åˆ¶å­—ç¬¦å’ŒANSIè½¬ä¹‰åºåˆ—"""
    if not text:
        return text

    ansi_escape = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
    text = ansi_escape.sub("", text)
    text = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]", "", text)
    text = text.replace("\r", "")
    return text


def _should_log_line(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è®°å½•è¿™è¡Œæ—¥å¿—ï¼Œè¿‡æ»¤çº¯è¿›åº¦æ¡ç­‰"""
    if not text or not text.strip():
        return False

    skip_patterns = [
        r"^\s*\|.*\|\s*\d+%.*$",
        r"^\s*\d+%.*\|.*$",
        r"^\s*[â–‡â–ˆâ–‘â–‰â–Šâ–‹â–Œâ–â–â–]+\s*$",
        r"^\s*\.{3,}\s*$",
        r"^\s*-{3,}\s*$",
        r"^\s*=+\s*$",
        r"^\s*\.$",
    ]
    for pattern in skip_patterns:
        if re.match(pattern, text):
            return False
    return True


def create_yolo_config(dataset_obj: Dataset, task_code: str) -> Optional[Path]:
    """
    ä¸ºæ•°æ®é›†åˆ›å»ºYOLOå…¼å®¹çš„é…ç½®æ–‡ä»¶

    Args:
        dataset_obj: æ•°æ®é›†å¯¹è±¡
        task_code: ä»»åŠ¡ä»£ç 

    Returns:
        YOLOé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ultra.yamlæ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        ultra_yaml_path = dataset_obj.path / f"{dataset_obj.name}.ultra.yaml"
        if ultra_yaml_path.exists():
            logger.info(f"å‘ç°ç°æœ‰çš„ultra.yamlé…ç½®æ–‡ä»¶: {ultra_yaml_path}")
            return ultra_yaml_path

        # è¯»å–æ•°æ®é›†å…ƒæ•°æ®
        metadata = dataset_obj.metadata
        if not metadata:
            logger.error(f"æ— æ³•è¯»å–æ•°æ®é›†å…ƒæ•°æ®: {dataset_obj.name}")
            return None

        # è·å–æ•°æ®é›†è·¯å¾„
        dataset_path = dataset_obj.path

        # æ£€æŸ¥æ•°æ®é›†çš„å®é™…ç›®å½•ç»“æ„
        images_dir = dataset_path / "images"
        labels_dir = dataset_path / "labels"

        if not images_dir.exists():
            logger.error(f"æ•°æ®é›† {dataset_obj.name} ç¼ºå°‘imagesç›®å½•: {images_dir}")
            return None

        # æ„å»ºYOLOé…ç½®ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
        yolo_config = {
            "path": str(dataset_path).replace("\\", "/"),  # YOLOä½¿ç”¨æ­£æ–œæ 
            "train": "images",  # ç›¸å¯¹äºpathçš„è·¯å¾„
            "val": "images",  # ç›¸å¯¹äºpathçš„è·¯å¾„
            "test": "images",  # ç›¸å¯¹äºpathçš„è·¯å¾„
            "names": {},
        }

        # å¤„ç†ç±»åˆ«åç§°
        if "class_names" in metadata:
            # å¦‚æœclass_namesæ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—å…¸
            class_names = metadata["class_names"]
            if isinstance(class_names, list):
                yolo_config["names"] = {i: name for i, name in enumerate(class_names)}
            elif isinstance(class_names, dict):
                yolo_config["names"] = class_names
        elif "classes" in metadata:
            yolo_config["names"] = metadata["classes"]
        else:
            # å°è¯•ä»classes.txtæ–‡ä»¶è¯»å–
            classes_file = dataset_path / "classes.txt"
            if classes_file.exists():
                with open(classes_file, "r", encoding="utf-8") as f:
                    class_list = [
                        line.strip() for line in f.readlines() if line.strip()
                    ]
                    yolo_config["names"] = {
                        i: name for i, name in enumerate(class_list)
                    }
            else:
                # é»˜è®¤ç±»åˆ«
                yolo_config["names"] = {0: "object"}

        # æ·»åŠ ç±»åˆ«æ•°é‡
        yolo_config["nc"] = len(yolo_config["names"])

        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        temp_config_path = PROJECT_DIR / "temp" / f"{dataset_obj.name}_yolo_config.yaml"
        temp_config_path.parent.mkdir(exist_ok=True)

        # å†™å…¥é…ç½®æ–‡ä»¶
        with open(temp_config_path, "w", encoding="utf-8") as f:
            yaml.dump(yolo_config, f, default_flow_style=False, allow_unicode=True)

        logger.info(f"ä¸ºæ•°æ®é›† {dataset_obj.name} åˆ›å»ºYOLOé…ç½®: {temp_config_path}")
        logger.info(f"é…ç½®å†…å®¹: {yolo_config}")
        return temp_config_path

    except Exception as e:
        logger.error(f"åˆ›å»ºYOLOé…ç½®å¤±è´¥: {e}")
        return None


def validate_environment() -> Tuple[bool, str]:
    """éªŒè¯YOLOéªŒè¯ç¯å¢ƒ"""
    try:
        # æ£€æŸ¥ultralytics
        import ultralytics

        return True, f"éªŒè¯ç¯å¢ƒæ­£å¸¸ (ultralytics {ultralytics.__version__})"
    except ImportError:
        return False, "ultralyticsåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install ultralytics"
    except Exception as e:
        return False, f"éªŒè¯ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {str(e)}"


# éªŒè¯çŠ¶æ€ç±»
class ValidationState:
    """éªŒè¯çŠ¶æ€ç®¡ç†"""

    # æ˜ç¡®å£°æ˜å±æ€§ç±»å‹ï¼Œä¾¿äºç±»å‹æ£€æŸ¥å™¨è¯†åˆ«
    is_running: bool
    current_task: Optional[str]
    results: Dict[str, Any]
    error_message: str
    completed_successfully: bool
    log_lines: List[str]
    current_epoch: int
    total_epochs: int
    start_time: Optional[float]
    end_time: Optional[float]
    process: Optional[subprocess.Popen]
    thread: Optional[threading.Thread]

    def __init__(self):
        self.is_running = False
        self.current_task = None
        self.results = {}
        self.error_message = ""
        self.completed_successfully = False
        self.log_lines = []
        self.current_epoch = 0
        self.total_epochs = 1
        self.start_time = None
        self.end_time = None
        self.process = None
        self.thread = None

    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        self.is_running = False
        self.current_task = None
        self.results = {}
        self.error_message = ""
        self.completed_successfully = False
        self.log_lines = []
        self.current_epoch = 0
        self.total_epochs = 1
        self.start_time = None
        self.end_time = None
        self.process = None
        self.thread = None

    def add_log(self, message: str):
        """æ·»åŠ æ—¥å¿—"""
        from datetime import datetime

        timestamp = datetime.now().strftime("%H:%M:%S")
        log_line = f"[{timestamp}] {message}"
        self.log_lines.append(log_line)
        logger.info(message)

    def get_recent_logs(self, count: int = 50) -> List[str]:
        """è·å–æœ€è¿‘çš„æ—¥å¿—"""
        return self.log_lines[-count:] if self.log_lines else []


# å…¨å±€éªŒè¯çŠ¶æ€å®ä¾‹
validation_state = ValidationState()


def start_validation(
    task_code: str,
    dataset_name: str,
    model_path: str,
    conf: float = 0.25,
    iou: float = 0.5,
    imgsz: int = 640,
    batch: int = 32,
    device: str = "auto",
    workers: int = 8,
    save_txt: bool = True,
    save_conf: bool = True,
    save_crop: bool = False,
    verbose: bool = True,
) -> Tuple[bool, str, Optional[Dict[str, Any]]]:
    """
    å¯åŠ¨YOLOæ¨¡å‹éªŒè¯

    Args:
        task_code: ä»»åŠ¡ä»£ç 
        dataset_name: æ•°æ®é›†åç§°
        model_path: æ¨¡å‹è·¯å¾„
        conf: ç½®ä¿¡åº¦é˜ˆå€¼
        iou: IoUé˜ˆå€¼
        imgsz: å›¾åƒå°ºå¯¸
        batch: æ‰¹å¤§å°
        device: è®¾å¤‡
        workers: å·¥ä½œè¿›ç¨‹æ•°
        save_txt: ä¿å­˜é¢„æµ‹ç»“æœæ–‡æœ¬
        save_conf: ä¿å­˜ç½®ä¿¡åº¦
        save_crop: ä¿å­˜è£å‰ªå›¾ç‰‡
        verbose: è¯¦ç»†è¾“å‡º

    Returns:
        (success: bool, message: str, results: Dict | None)
    """
    global validation_state

    try:
        # é‡ç½®å¹¶æ ‡è®°å¯åŠ¨
        validation_state.reset()
        validation_state.is_running = True
        validation_state.current_task = task_code
        validation_state.add_log(f"å¼€å§‹éªŒè¯ä»»åŠ¡: {task_code}")

        # è·å–æ•°æ®é›†ä¿¡æ¯
        dataset_obj = dataset_manager.get_dataset(dataset_name)
        if dataset_obj is None or not dataset_obj.exists:
            msg = (
                f"æ•°æ®é›†æœªæ‰¾åˆ°: {dataset_name}"
                if dataset_obj is None
                else f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_obj.path}"
            )
            validation_state.error_message = msg
            validation_state.add_log(f"âŒ {msg}")
            validation_state.is_running = False
            return False, msg, None

        if not dataset_obj.metadata_exists:
            msg = f"æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_obj.metadata_path}"
            validation_state.error_message = msg
            validation_state.add_log(f"âŒ {msg}")
            validation_state.is_running = False
            return False, msg, None

        validation_state.add_log(f"âœ… æ•°æ®é›†æ£€æŸ¥é€šè¿‡: {dataset_name}")

        # åˆ›å»ºYOLOé…ç½®
        validation_state.add_log("ğŸ”„ åˆ›å»ºYOLOé…ç½®æ–‡ä»¶...")
        yolo_config = create_yolo_config(dataset_obj, task_code)
        if yolo_config is None:
            msg = f"æ— æ³•ä¸ºæ•°æ®é›† {dataset_name} åˆ›å»ºYOLOé…ç½®"
            validation_state.error_message = msg
            validation_state.add_log(f"âŒ {msg}")
            validation_state.is_running = False
            return False, msg, None
        validation_state.add_log(f"âœ… YOLOé…ç½®æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {yolo_config}")

        # æ£€æŸ¥æ¨¡å‹
        if not Path(model_path).exists():
            msg = f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"
            validation_state.error_message = msg
            validation_state.add_log(f"âŒ {msg}")
            validation_state.is_running = False
            return False, msg, None
        validation_state.add_log(f"âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡: {model_path}")

        # åˆ›å»ºè¿è¡Œç›®å½•
        runs_dir = PROJECT_DIR / "runs" / "val" / task_code
        runs_dir.mkdir(parents=True, exist_ok=True)
        validation_state.add_log(f"ğŸ“ è¾“å‡ºç›®å½•: {runs_dir}")

        # è®¾å¤‡é€‰æ‹©
        resolved_device = device
        if device == "auto":
            try:
                import torch  # type: ignore

                if torch.cuda.is_available() and torch.cuda.device_count() > 0:
                    resolved_device = "0"
                else:
                    resolved_device = "cpu"
            except Exception:
                resolved_device = "cpu"

        # è®°å½•å‚æ•°
        validation_state.add_log("ğŸ“‹ éªŒè¯å‚æ•°:")
        validation_state.add_log(f"  - ç½®ä¿¡åº¦é˜ˆå€¼: {conf}")
        validation_state.add_log(f"  - IoUé˜ˆå€¼: {iou}")
        validation_state.add_log(f"  - å›¾åƒå°ºå¯¸: {imgsz}")
        validation_state.add_log(f"  - æ‰¹å¤§å°: {batch}")
        validation_state.add_log(f"  - è®¾å¤‡: {resolved_device}")

        # æ„å»ºå‘½ä»¤
        yolo_exe = Path(sys.executable).parent / "yolo.exe"
        if not yolo_exe.exists():
            # å›é€€åˆ° Python APIï¼Œä½†ä»ä¿æŒå¼‚æ­¥çº¿ç¨‹ä»¥æ¨é€æ—¥å¿—
            def run_python_api():
                try:
                    validation_state.add_log("ğŸ”„ åŠ è½½YOLOåº“...")
                    from ultralytics import YOLO  # type: ignore

                    validation_state.add_log("ğŸ”„ åŠ è½½æ¨¡å‹...")
                    model = YOLO(model_path)
                    validation_state.add_log("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                    validation_state.add_log("ğŸš€ å¼€å§‹éªŒè¯...")
                    validation_state.current_epoch = 0
                    validation_state.total_epochs = 1

                    results = model.val(
                        data=str(yolo_config),
                        conf=conf,
                        iou=iou,
                        imgsz=imgsz,
                        batch=batch,
                        device=resolved_device,
                        workers=workers,
                        save_txt=save_txt,
                        save_conf=save_conf,
                        save_crop=save_crop,
                        project=str(runs_dir.parent),
                        name=task_code,
                        exist_ok=True,
                        verbose=verbose,
                    )

                    validation_state.current_epoch = 1
                    validation_state.add_log("âœ… éªŒè¯æ‰§è¡Œå®Œæˆ")

                    # æå–ç»“æœ
                    validation_state.add_log("ğŸ”„ æå–éªŒè¯ç»“æœ...")
                    validation_results: Dict[str, Any] = {}
                    if hasattr(results, "results_dict"):
                        validation_results = results.results_dict  # type: ignore[attr-defined]
                    elif hasattr(results, "box"):
                        box_results = results.box  # type: ignore[attr-defined]
                        validation_results = {
                            "mAP50": float(getattr(box_results, "map50", 0.0)),
                            "mAP50-95": float(getattr(box_results, "map", 0.0)),
                            "precision": float(getattr(box_results, "mp", 0.0)),
                            "recall": float(getattr(box_results, "mr", 0.0)),
                            "f1": float(getattr(box_results, "f1", 0.0)),
                        }

                    formatted_results: Dict[str, Any] = {}
                    for k, v in validation_results.items():
                        formatted_results[k] = (
                            round(float(v), 4)
                            if isinstance(v, (int, float))
                            else str(v)
                        )

                    validation_state.results = formatted_results
                    validation_state.completed_successfully = True
                    validation_state.add_log("ğŸ‰ éªŒè¯ç»“æœ:")
                    for key, value in formatted_results.items():
                        validation_state.add_log(f"  - {key}: {value}")
                    validation_state.add_log("âœ… éªŒè¯ä»»åŠ¡å®Œæˆ")
                except ImportError:
                    msg = "ultralyticsåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install ultralytics"
                    validation_state.error_message = msg
                    validation_state.add_log(f"âŒ {msg}")
                    validation_state.completed_successfully = False
                except Exception as e:
                    validation_state.error_message = f"éªŒè¯å¤±è´¥: {e}"
                    validation_state.add_log(f"âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
                    validation_state.completed_successfully = False
                finally:
                    validation_state.is_running = False
                    validation_state.process = None

            validation_state.thread = threading.Thread(
                target=run_python_api, daemon=True
            )
            validation_state.thread.start()
            return True, "éªŒè¯å·²å¼€å§‹ (Python API)", None

        # ä½¿ç”¨CLIæ–¹å¼è¿è¡Œï¼Œå®æ—¶è¯»å–è¾“å‡º
        val_args: List[str] = [
            str(yolo_exe),
            "val",
            f"data={yolo_config}",
            f"model={model_path}",
            f"conf={conf}",
            f"iou={iou}",
            f"imgsz={imgsz}",
            f"batch={batch}",
            f"device={resolved_device}",
            f"workers={workers}",
            f"save_txt={(str(save_txt).lower())}",
            f"save_conf={(str(save_conf).lower())}",
            f"save_crop={(str(save_crop).lower())}",
            f"project={str((PROJECT_DIR / 'runs' / 'val').resolve())}",
            f"name={task_code}",
            "exist_ok=True",
        ]

        def parse_results_files(out_dir: Path) -> Dict[str, Any]:
            # ä¼˜å…ˆè¯»å– results.jsonï¼Œå…¶æ¬¡ results.csv
            results_json = out_dir / "results.json"
            if results_json.exists():
                try:
                    with open(results_json, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    flat: Dict[str, Any] = {}
                    # å¸¸è§å­—æ®µæ˜ å°„
                    mappings = {
                        "metrics/precision(B)": "precision",
                        "metrics/recall(B)": "recall",
                        "metrics/mAP50(B)": "mAP50",
                        "metrics/mAP50-95(B)": "mAP50-95",
                    }
                    for k, v in data.items():
                        key = str(mappings.get(k, k))
                        flat[key] = v
                    return flat
                except Exception:
                    pass

            results_csv = out_dir / "results.csv"
            if results_csv.exists():
                try:
                    lines = (
                        results_csv.read_text(encoding="utf-8", errors="ignore")
                        .strip()
                        .splitlines()
                    )
                    if len(lines) >= 2:
                        headers = [h.strip() for h in lines[0].split(",")]
                        values = [v.strip() for v in lines[-1].split(",")]
                        mapping: Dict[str, Any] = {}
                        for h, v in zip(headers, values):
                            try:
                                mapping[h] = float(v)
                            except Exception:
                                mapping[h] = v
                        # å¸¸è§åˆ—é‡å‘½å
                        rename = {
                            "metrics/precision(B)": "precision",
                            "metrics/recall(B)": "recall",
                            "metrics/mAP50(B)": "mAP50",
                            "metrics/mAP50-95(B)": "mAP50-95",
                        }
                        return {rename.get(k, k): v for k, v in mapping.items()}
                except Exception:
                    pass
            return {}

        def run_cli():
            try:
                env = os.environ.copy()
                env["PYTHONIOENCODING"] = "utf-8"
                env["TERM"] = "dumb"
                env["COLUMNS"] = "120"
                env["LINES"] = "32"

                validation_state.add_log("ğŸš€ è°ƒç”¨å‘½ä»¤è¡Œå¼€å§‹éªŒè¯...")
                validation_state.current_epoch = 0
                validation_state.total_epochs = 1

                validation_state.process = subprocess.Popen(
                    val_args,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding="utf-8",
                    errors="replace",
                    cwd=PROJECT_DIR,
                    env=env,
                    universal_newlines=True,
                )

                if validation_state.process.stdout:
                    for raw in iter(validation_state.process.stdout.readline, ""):
                        if not validation_state.is_running:
                            break
                        line = _clean_terminal_output(raw.rstrip("\n"))
                        if _should_log_line(line):
                            from datetime import datetime as _dt

                            ts = _dt.now().strftime("%H:%M:%S")
                            validation_state.log_lines.append(f"[{ts}] {line}")

                rc = validation_state.process.wait()

                # è§£æç»“æœæ–‡ä»¶
                out_dir = PROJECT_DIR / "runs" / "val" / task_code
                results_map = parse_results_files(out_dir)
                if results_map:
                    validation_state.results = {
                        k: (round(float(v), 4) if isinstance(v, (int, float)) else v)
                        for k, v in results_map.items()
                    }
                    if "mAP50" in validation_state.results:
                        # ä¾›ä¸Šå±‚æ˜¾ç¤º
                        pass

                validation_state.completed_successfully = rc == 0
                if rc == 0:
                    validation_state.add_log("âœ… éªŒè¯ä»»åŠ¡å®Œæˆ")
                else:
                    validation_state.add_log(f"âŒ éªŒè¯è¿›ç¨‹è¿”å›ç : {rc}")

            except Exception as e:
                validation_state.completed_successfully = False
                validation_state.error_message = f"éªŒè¯æ‰§è¡Œå¤±è´¥: {e}"
                validation_state.add_log(f"âŒ {validation_state.error_message}")
            finally:
                validation_state.is_running = False
                validation_state.process = None

        validation_state.thread = threading.Thread(target=run_cli, daemon=True)
        validation_state.thread.start()
        return True, "éªŒè¯å·²å¼€å§‹ (CLI)", None

    except Exception as e:
        msg = f"éªŒè¯å¯åŠ¨å¤±è´¥: {e}"
        validation_state.error_message = msg
        validation_state.add_log(f"âŒ {msg}")
        validation_state.is_running = False
        return False, msg, None


def stop_validation() -> Tuple[bool, str]:
    """åœæ­¢æ­£åœ¨è¿›è¡Œçš„éªŒè¯ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰"""
    if not validation_state.is_running:
        return False, "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„éªŒè¯ä»»åŠ¡"
    try:
        if validation_state.process and validation_state.process.poll() is None:
            validation_state.process.terminate()
            try:
                validation_state.process.wait(timeout=10)
            except subprocess.TimeoutExpired:
                validation_state.process.kill()
        validation_state.is_running = False
        validation_state.add_log("â¹ï¸ éªŒè¯å·²åœæ­¢")
        return True, "éªŒè¯å·²åœæ­¢"
    except Exception as e:
        return False, f"åœæ­¢éªŒè¯å¤±è´¥: {e}"
