"""æ¨¡å‹ç®¡ç†æ¨¡å—"""

from __future__ import annotations

# é…ç½®æ—¥å¿—
import logging
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Tuple

import yaml

from .paths import MODELS_PRETRAINED_DIR, MODELS_TRAINED_DIR

logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
MODEL_EXTS = {".pt", ".onnx", ".engine", ".xml", ".bin"}


def _read_yaml_top_level_value(p: Path, key: str) -> Optional[str]:
    """ä»YAMLæ–‡ä»¶ä¸­è¯»å–é¡¶çº§é”®å€¼"""
    if not p.exists():
        return None
    try:
        with open(p, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        if isinstance(data, dict) and key in data:
            return str(data[key])
    except Exception:
        return None
    return None


def model_task_code_from_sidecar(model_path: Path) -> Optional[str]:
    """ä»æ¨¡å‹çš„sidecaræ–‡ä»¶ä¸­è·å–ä»»åŠ¡ç±»å‹ä»£ç """
    side = model_path.with_suffix("")
    yml = side.parent / f"{side.name}.yml"
    return _read_yaml_top_level_value(yml, "task")


def list_models_for_task(task_code: str) -> List[Tuple[str, str]]:
    """è¿”å›æŒ‡å®šä»»åŠ¡ç±»å‹çš„æ¨¡å‹åˆ—è¡¨ï¼Œæ ¼å¼ä¸º(æ ‡ç­¾, è·¯å¾„)"""
    results: List[Tuple[str, str]] = []
    for is_pre, base in ((True, MODELS_PRETRAINED_DIR), (False, MODELS_TRAINED_DIR)):
        if not base.exists():
            continue
        for f in sorted(base.iterdir()):
            if f.is_file() and f.suffix.lower() in MODEL_EXTS:
                t = model_task_code_from_sidecar(f)
                if t == task_code:
                    label = ("[é¢„è®­ç»ƒ] " if is_pre else "[è®­ç»ƒ] ") + f.name
                    results.append((label, str(f)))
    return results


# Ultralyticsé¢„è®­ç»ƒæ¨¡å‹é€‰æ‹©
ULTRALYTICS_PRETRAINED_CHOICES = {
    # detect
    "YOLOv8n (detect)": "yolov8n.pt",
    "YOLOv8s (detect)": "yolov8s.pt",
    "YOLOv8m (detect)": "yolov8m.pt",
    "YOLOv8l (detect)": "yolov8l.pt",
    "YOLOv8x (detect)": "yolov8x.pt",
    # YOLO11
    "YOLO11n (detect)": "yolo11n.pt",
    "YOLO11s (detect)": "yolo11s.pt",
    "YOLO11m (detect)": "yolo11m.pt",
    "YOLO11l (detect)": "yolo11l.pt",
    "YOLO11x (detect)": "yolo11x.pt",
}

# æ¨¡å‹ä»»åŠ¡æ˜ å°„
MODEL_TASK_MAP = {
    "å›¾åƒåˆ†ç±»": "classify",
    "ç›®æ ‡æ£€æµ‹": "detect",
    "å›¾åƒåˆ†å‰²": "segment",
    "å…³é”®ç‚¹è·Ÿè¸ª": "pose",
    "æ—‹è½¬æ£€æµ‹æ¡†è¯†åˆ«": "obb",
}


def list_models(dir_path: Path) -> List[str]:
    """è·å–ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶ååˆ—è¡¨"""
    if not dir_path.exists():
        return []
    return [
        p.name
        for p in sorted(dir_path.iterdir())
        if p.is_file()
        and p.suffix.lower() in {".pt", ".onnx", ".engine", ".xml", ".bin"}
    ]


def get_model_details(dir_path: Path) -> List[List[str]]:
    """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å«æ–‡ä»¶åã€æè¿°ã€åˆ›å»ºæ—¥æœŸ"""
    if not dir_path.exists():
        return []

    details = []
    for p in sorted(dir_path.iterdir()):
        if p.is_file() and p.suffix.lower() in {
            ".pt",
            ".onnx",
            ".engine",
            ".xml",
            ".bin",
        }:
            name = p.name

            # è¯»å–æè¿°ä¿¡æ¯
            meta_file = p.with_suffix("")
            yml_path = meta_file.parent / f"{meta_file.name}.yml"
            description = "æ— æè¿°"
            if yml_path.exists():
                desc = _read_yaml_top_level_value(yml_path, "description")
                if desc:
                    description = desc

            # è·å–åˆ›å»ºæ—¶é—´
            try:
                created_time = datetime.fromtimestamp(p.stat().st_mtime)
                created_str = created_time.strftime("%Y-%m-%d %H:%M")
            except Exception:
                created_str = "æœªçŸ¥"

            details.append([name, description, created_str])

    return details


def get_all_models_info() -> dict:
    """è·å–æ‰€æœ‰æ¨¡å‹çš„å®Œæ•´ä¿¡æ¯"""
    result = {"pretrained": [], "trained": []}

    # å¤„ç†é¢„è®­ç»ƒæ¨¡å‹
    if MODELS_PRETRAINED_DIR.exists():
        for p in sorted(MODELS_PRETRAINED_DIR.iterdir()):
            if p.is_file() and p.suffix.lower() in {
                ".pt",
                ".onnx",
                ".engine",
                ".xml",
                ".bin",
            }:
                model_info = _extract_model_info(p, is_pretrained=True)
                if model_info:
                    result["pretrained"].append(model_info)

    # å¤„ç†è®­ç»ƒæ¨¡å‹
    if MODELS_TRAINED_DIR.exists():
        for p in sorted(MODELS_TRAINED_DIR.iterdir()):
            if p.is_file() and p.suffix.lower() in {
                ".pt",
                ".onnx",
                ".engine",
                ".xml",
                ".bin",
            }:
                model_info = _extract_model_info(p, is_pretrained=False)
                if model_info:
                    result["trained"].append(model_info)

    return result


def _extract_model_info(model_path: Path, is_pretrained: bool) -> Optional[dict]:
    """æå–å•ä¸ªæ¨¡å‹çš„å®Œæ•´ä¿¡æ¯"""
    try:
        # åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
        filename = model_path.name
        stem = model_path.stem

        # æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
        stat = model_path.stat()
        file_size = stat.st_size / (1024 * 1024)  # MB
        created_time = datetime.fromtimestamp(stat.st_mtime)

        # è¯»å–å…ƒæ•°æ®
        yml_path = model_path.with_suffix(".yml")
        metadata = {}
        description = "æ— æè¿°"
        if yml_path.exists():
            try:
                with open(yml_path, "r", encoding="utf-8") as f:
                    metadata = yaml.safe_load(f) or {}
                # è·å–æè¿°ï¼Œå¦‚æœå¤ªé•¿åˆ™åœ¨è¡¨æ ¼ä¸­æ˜¾ç¤ºä¸º "|"
                desc = metadata.get("description", "")
                if desc:
                    description = "|" if len(desc) > 50 else desc
            except Exception as e:
                logger.warning(f"è¯»å–æ¨¡å‹å…ƒæ•°æ®å¤±è´¥ {yml_path}: {e}")

        return {
            "filename": filename,
            "stem": stem,
            "file_size_mb": file_size,
            "created_time": created_time,
            "created_str": created_time.strftime("%Y-%m-%d %H:%M"),
            "description": description,
            "full_description": metadata.get("description", ""),
            "metadata": metadata,
            "is_pretrained": is_pretrained,
            "model_path": model_path,
            "yml_path": yml_path,
        }
    except Exception as e:
        logger.error(f"æå–æ¨¡å‹ä¿¡æ¯å¤±è´¥ {model_path}: {e}")
        return None


def get_model_detail(model_name: str, is_pretrained: bool = True) -> str:
    """è·å–æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
    if not model_name:
        return ""

    # é€‰æ‹©ç›®å½•
    base_dir = MODELS_PRETRAINED_DIR if is_pretrained else MODELS_TRAINED_DIR

    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_file = None
    for suffix in [".pt", ".onnx", ".engine", ".xml", ".bin"]:
        candidate = base_dir / f"{model_name}{suffix}"
        if candidate.exists():
            model_file = candidate
            break

    if not model_file:
        return f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_name}"

    # è¯»å–å…ƒæ•°æ®
    yml_path = model_file.with_suffix(".yml")
    metadata = {}
    if yml_path.exists():
        try:
            with open(yml_path, "r", encoding="utf-8") as f:
                metadata = yaml.safe_load(f) or {}
        except Exception as e:
            logger.warning(f"è¯»å–æ¨¡å‹å…ƒæ•°æ®å¤±è´¥ {yml_path}: {e}")

    # è·å–æ–‡ä»¶ä¿¡æ¯
    try:
        file_size = model_file.stat().st_size
        size_mb = file_size / (1024 * 1024)
        created_time = datetime.fromtimestamp(model_file.stat().st_mtime)
        modified_time = datetime.fromtimestamp(model_file.stat().st_ctime)
    except Exception:
        size_mb = 0
        created_time = datetime.now()
        modified_time = datetime.now()

    # æ„å»ºè¯¦ç»†ä¿¡æ¯
    info_lines = [
        f"# ğŸ“¦ æ¨¡å‹è¯¦ç»†ä¿¡æ¯",
        f"",
        f"**æ¨¡å‹åç§°:** {model_name}",
        f"**æ–‡ä»¶è·¯å¾„:** `{model_file}`",
        f"**æ–‡ä»¶å¤§å°:** {size_mb:.2f} MB",
        f"**åˆ›å»ºæ—¶é—´:** {created_time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**ä¿®æ”¹æ—¶é—´:** {modified_time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ¨¡å‹ç±»å‹:** {'é¢„è®­ç»ƒæ¨¡å‹' if is_pretrained else 'è®­ç»ƒæ¨¡å‹'}",
        f"",
    ]

    # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
    if metadata:
        info_lines.append("## ğŸ“‹ å…ƒæ•°æ®ä¿¡æ¯")

        # åŸºæœ¬ä¿¡æ¯
        if "task" in metadata:
            task_display = metadata.get("task_display", metadata["task"])
            info_lines.append(f"**ä»»åŠ¡ç±»å‹:** {task_display}")

        if "version" in metadata:
            info_lines.append(f"**YOLOç‰ˆæœ¬:** {metadata['version']}")

        if "size" in metadata:
            info_lines.append(f"**æ¨¡å‹å¤§å°:** {metadata['size']}")

        if "description" in metadata:
            desc = metadata["description"]
            info_lines.append(f"**æè¿°:**")
            # å¤„ç†å¤šè¡Œæè¿°
            if isinstance(desc, str):
                # æ¸…ç†æè¿°å†…å®¹ï¼Œå»æ‰å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
                cleaned_desc = desc.strip()
                for line in cleaned_desc.split("\n"):
                    line = line.strip()
                    if line:  # åªæ·»åŠ éç©ºè¡Œ
                        info_lines.append(f"> {line}")
            else:
                info_lines.append(f"> {desc}")

        # è®­ç»ƒç›¸å…³ä¿¡æ¯ï¼ˆä»…è®­ç»ƒæ¨¡å‹ï¼‰
        if not is_pretrained:
            if "base_model" in metadata:
                info_lines.append(f"**åŸºç¡€æ¨¡å‹:** {metadata['base_model']}")
            if "dataset" in metadata:
                info_lines.append(f"**è®­ç»ƒæ•°æ®é›†:** {metadata['dataset']}")
            if "epochs_trained" in metadata:
                info_lines.append(f"**è®­ç»ƒè½®æ¬¡:** {metadata['epochs_trained']}")
            if "training_date" in metadata:
                info_lines.append(f"**è®­ç»ƒæ—¥æœŸ:** {metadata['training_date']}")
            if "model_type" in metadata:
                model_type_display = {"best": "æœ€ä½³æƒé‡", "latest": "æœ€æ–°æƒé‡"}.get(
                    metadata["model_type"], metadata["model_type"]
                )
                info_lines.append(f"**æƒé‡ç±»å‹:** {model_type_display}")

        info_lines.append("")

        # å®Œæ•´å…ƒæ•°æ®
        info_lines.append("## ğŸ”§ å®Œæ•´å…ƒæ•°æ®")
        info_lines.append("```yaml")
        try:
            yaml_content = yaml.safe_dump(
                metadata, allow_unicode=True, default_flow_style=False
            )
            info_lines.append(yaml_content)
        except Exception:
            info_lines.append("æ— æ³•æ˜¾ç¤ºå…ƒæ•°æ®")
        info_lines.append("```")
    else:
        info_lines.append("## âš ï¸ å…ƒæ•°æ®ä¿¡æ¯")
        info_lines.append("")
        info_lines.append("æ­¤æ¨¡å‹æ²¡æœ‰å…³è”çš„å…ƒæ•°æ®æ–‡ä»¶(.yml)")

    return "\n\n".join(info_lines)


def refresh_model_lists() -> tuple[list[str], list[str]]:
    """è·å–æ¨¡å‹åç§°åˆ—è¡¨ (ç”¨äºä¸‹æ‹‰æ¡†)"""
    return list_models(MODELS_PRETRAINED_DIR), list_models(MODELS_TRAINED_DIR)


def refresh_model_details() -> tuple[list[list[str]], list[list[str]]]:
    """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯åˆ—è¡¨ (ç”¨äºè¡¨æ ¼æ˜¾ç¤º)"""
    return get_model_details(MODELS_PRETRAINED_DIR), get_model_details(
        MODELS_TRAINED_DIR
    )


def download_pretrained_if_missing(name_or_path: str) -> tuple[bool, str, str]:
    """é€šè¿‡ultralyticsä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹"""
    try:
        from ultralytics import YOLO

        m = YOLO(name_or_path)
        ckpt_path = getattr(m, "ckpt_path", None)
        if not ckpt_path:
            ckpt_path = name_or_path

        src = Path(ckpt_path)
        if not src.exists():
            return False, "æœªæ‰¾åˆ°ä¸‹è½½åçš„æƒé‡æ–‡ä»¶", ""

        MODELS_PRETRAINED_DIR.mkdir(parents=True, exist_ok=True)
        dest = MODELS_PRETRAINED_DIR / src.name

        if not dest.exists():
            shutil.copy2(src, dest)

        return True, f"å·²å‡†å¤‡é¢„è®­ç»ƒæ¨¡å‹: {dest.name}", dest.name

    except Exception as e:
        return False, f"ä¸‹è½½å¤±è´¥ï¼š{e}", ""


def delete_model(is_pretrained: bool, filename: str) -> tuple[bool, str]:
    """åˆ é™¤æ¨¡å‹æ–‡ä»¶"""
    base = MODELS_PRETRAINED_DIR if is_pretrained else MODELS_TRAINED_DIR
    p = base / filename
    if not p.exists():
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"

    try:
        p.unlink()
        # åˆ é™¤å¯¹åº”çš„YAMLæ–‡ä»¶
        side = base / f"{p.stem}.yml"
        if side.exists():
            try:
                side.unlink()
            except Exception:
                pass
        return True, "å·²åˆ é™¤"
    except Exception as e:
        return False, f"åˆ é™¤å¤±è´¥ï¼š{e}"


def rename_model(is_pretrained: bool, old: str, new: str) -> tuple[bool, str, str]:
    """é‡å‘½åæ¨¡å‹æ–‡ä»¶"""
    base = MODELS_PRETRAINED_DIR if is_pretrained else MODELS_TRAINED_DIR
    src = base / old
    if not src.exists():
        return False, old, "æ–‡ä»¶ä¸å­˜åœ¨"

    dest = base / new
    if dest.exists():
        # åˆ›å»ºå”¯ä¸€åç§°
        i = 1
        stem, suf = dest.stem, dest.suffix
        while (base / f"{stem}_{i}{suf}").exists():
            i += 1
        dest = base / f"{stem}_{i}{suf}"

    try:
        shutil.move(str(src), str(dest))

        # é‡å‘½åå¯¹åº”çš„YAMLæ–‡ä»¶
        old_yaml = base / f"{src.stem}.yml"
        new_yaml = base / f"{dest.stem}.yml"
        if old_yaml.exists():
            try:
                shutil.move(str(old_yaml), str(new_yaml))
            except Exception:
                pass

        return True, dest.name, "å·²é‡å‘½å"
    except Exception as e:
        return False, old, f"é‡å‘½åå¤±è´¥ï¼š{e}"


def model_meta_path(is_pretrained: bool, stem: str) -> Path:
    """è·å–æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
    base = MODELS_PRETRAINED_DIR if is_pretrained else MODELS_TRAINED_DIR
    return base / f"{stem}.yml"


def build_model_metadata_yaml(
    name: str,
    task_display: str,
    task_code: str,
    version: str,
    size: str,
    description: str,
) -> str:
    """æ„å»ºæ¨¡å‹å…ƒæ•°æ®YAML"""
    created_at = datetime.utcnow().isoformat() + "Z"
    data = {
        "name": name,
        "task": task_code,
        "task_display": task_display,
        "version": version,
        "size": size,
        "description": description,
        "created_at": created_at,
    }
    return yaml.safe_dump(data, allow_unicode=True, default_flow_style=False)


def compute_ultra_weight_name(task_code: str, version: str, size: str) -> str:
    """è®¡ç®—Ultralyticsæƒé‡æ–‡ä»¶å"""
    v = version.lower().strip()
    if v not in {"v8", "11"}:
        v = "v8"
    prefix = "yolov8" if v == "v8" else "yolo11"

    suffix = {
        "classify": "",
        "detect": "",
        "segment": "-seg",
        "pose": "-pose",
        "obb": "-obb",
    }.get(task_code, "")

    size_code = size.lower().strip()[0]  # n/s/m/l/x
    return f"{prefix}{size_code}{suffix}.pt"


def download_and_register_pretrained(
    task_display: str,
    version: str,
    size: str,
    custom_name: str,
    description: str,
    progress_cb=None,
) -> tuple[bool, str]:
    """ä¸‹è½½å¹¶æ³¨å†Œé¢„è®­ç»ƒæ¨¡å‹"""
    task_code = MODEL_TASK_MAP.get(task_display, "detect")
    weight = compute_ultra_weight_name(task_code, version, size)

    if progress_cb:
        try:
            progress_cb(0.1, f"å‡†å¤‡ä¸‹è½½ {weight}")
        except Exception:
            pass

    ok, msg, saved = download_pretrained_if_missing(weight)
    if not ok:
        return False, msg

    # é‡å‘½åæ–‡ä»¶
    src = MODELS_PRETRAINED_DIR / saved
    final_file = src
    if custom_name:
        desired = MODELS_PRETRAINED_DIR / (custom_name.strip() + src.suffix)
        if desired.exists():
            i = 1
            while (
                MODELS_PRETRAINED_DIR / f"{custom_name.strip()}_{i}{src.suffix}"
            ).exists():
                i += 1
            desired = MODELS_PRETRAINED_DIR / f"{custom_name.strip()}_{i}{src.suffix}"
        shutil.move(str(src), str(desired))
        final_file = desired

    # å†™å…¥å…ƒæ•°æ®
    stem = final_file.stem
    meta_yaml = build_model_metadata_yaml(
        name=stem,
        task_display=task_display,
        task_code=task_code,
        version=version,
        size=size,
        description=description or "",
    )
    model_meta_path(True, stem).write_text(meta_yaml, encoding="utf-8")

    if progress_cb:
        try:
            progress_cb(1.0, f"å®Œæˆï¼š{final_file.name}")
        except Exception:
            pass

    return True, f"å·²å‡†å¤‡é¢„è®­ç»ƒæ¨¡å‹ï¼š{final_file.name}"


__all__ = [
    "ULTRALYTICS_PRETRAINED_CHOICES",
    "MODEL_TASK_MAP",
    "list_models",
    "get_model_details",
    "refresh_model_lists",
    "refresh_model_details",
    "download_pretrained_if_missing",
    "delete_model",
    "rename_model",
    "download_and_register_pretrained",
    "build_model_metadata_yaml",
]
